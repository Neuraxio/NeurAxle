{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest API Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from neuraxle.api.flask import FlaskRestApiWrapper, JSONDataBodyDecoder, JSONDataResponseEncoder\n",
    "from neuraxle.pipeline import Pipeline\n",
    "from neuraxle.steps.sklearn import SKLearnWrapper, RidgeModelStacking\n",
    "from neuraxle.union import AddFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X, y = shuffle(boston.data, boston.target, random_state=13)\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    AddFeatures([\n",
    "        SKLearnWrapper(PCA(n_components=2)),\n",
    "        SKLearnWrapper(FastICA(n_components=2)),\n",
    "    ]),\n",
    "    RidgeModelStacking([\n",
    "        SKLearnWrapper(GradientBoostingRegressor()),\n",
    "        SKLearnWrapper(KMeans()),\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting on train:\")\n",
    "pipeline = pipeline.fit(X_train, y_train)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Transforming train and test:\")\n",
    "y_train_predicted = pipeline.transform(X_train)\n",
    "y_test_predicted = pipeline.transform(X_test)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluating transformed train:\")\n",
    "score = r2_score(y_train_predicted, y_train)\n",
    "print('R2 regression score:', score)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluating transformed test:\")\n",
    "score = r2_score(y_test_predicted, y_test)\n",
    "print('R2 regression score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step to decode json \n",
    "\n",
    "CustomJSONDecoderFor2DArray maps the request body json to the expected data inputs format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJSONDecoderFor2DArray(JSONDataBodyDecoder):\n",
    "    \"\"\"This is a custom JSON decoder class that precedes the pipeline's transformation.\"\"\"\n",
    "\n",
    "    def decode(self, data_inputs):\n",
    "        \"\"\"\n",
    "        Transform json object into an np array.\n",
    "\n",
    "        :param data_inputs: json object\n",
    "        :return: np array for data inputs\n",
    "        \"\"\"\n",
    "        return np.array(data_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step to encode json response\n",
    "\n",
    "CustomJSONEncoderOfOutputs returns a flask Response object that contains the encoded data inputs (predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomJSONEncoderOfOutputs(JSONDataResponseEncoder):\n",
    "    \"\"\"This is a custom JSON response encoder class for converting the pipeline's transformation outputs.\"\"\"\n",
    "\n",
    "    def encode(self, data_inputs) -> dict:\n",
    "        \"\"\"\n",
    "        Returns the response dict for the flask Response object.\n",
    "\n",
    "        :param data_inputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'predictions': list(data_inputs)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve Predictions\n",
    "\n",
    "FlaskRestApiWrapper will create a flask app that calls the wrapped pipeline transform method on each post request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FlaskRestApiWrapper(\n",
    "    json_decoder=CustomJSONDecoderFor2DArray(),\n",
    "    wrapped=pipeline,\n",
    "    json_encoder=CustomJSONEncoderOfOutputs(),\n",
    "    route='/'\n",
    ").get_app()\n",
    "\n",
    "app.run(debug=False, port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Api Call Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictictions = requests.post(\n",
    "    url='http://127.0.0.1:5000/',\n",
    "    json=X_test.tolist()\n",
    ")\n",
    "print(test_predictictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
